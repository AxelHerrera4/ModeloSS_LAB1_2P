name: ğŸ›¡ï¸ Security Vulnerability Scanner CI/CD

on:
  push:
    branches: [ main, develop, master ]
    paths:
      - '**.py'
      - '**.js'
  pull_request:
    branches: [ main, develop, master ]
    paths:
      - '**.py'
      - '**.js'
  workflow_dispatch:

permissions:
  contents: read
  issues: write
  pull-requests: write
  checks: write

env:
  PYTHON_VERSION: '3.11'
  MODEL_PATH: 'ml_model/vulnerability_detector.pkl'
  RISK_THRESHOLD: '0.70'

jobs:
  vulnerability-scan:
    name: ğŸ” ML Security Analysis
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Necesario para git diff
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: ğŸ” Get changed files
        id: changed-files
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "Analizando archivos cambiados en PR..."
            python scripts/get_changed_files.py \
              --base ${{ github.event.pull_request.base.sha }} \
              --head ${{ github.event.pull_request.head.sha }} \
              --output changed_files.json
          else
            echo "Analizando archivos cambiados en push..."
            python scripts/get_changed_files.py \
              --base ${{ github.event.before }} \
              --head ${{ github.sha }} \
              --output changed_files.json
          fi
          
          # Verificar si hay archivos para escanear
          FILE_COUNT=$(jq -r '.scannable' changed_files.json)
          echo "files_count=$FILE_COUNT" >> $GITHUB_OUTPUT
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "âš ï¸ No hay archivos Python/JavaScript para escanear"
            echo "has_files=false" >> $GITHUB_OUTPUT
          else
            echo "âœ… Archivos a escanear: $FILE_COUNT"
            echo "has_files=true" >> $GITHUB_OUTPUT
          fi
      
      - name: ğŸ§  Verify ML Model
        if: steps.changed-files.outputs.has_files == 'true'
        run: |
          if [ ! -f "${{ env.MODEL_PATH }}" ]; then
            echo "âŒ Modelo no encontrado en ${{ env.MODEL_PATH }}"
            echo "Por favor, entrena el modelo ejecutando: python ml_model/model.py"
            echo "O sube el archivo .pkl al repositorio"
            exit 1
          else
            echo "âœ… Modelo encontrado: ${{ env.MODEL_PATH }}"
          fi
      
      - name: ğŸ” Run Vulnerability Scan on Changed Files
        id: scan
        if: steps.changed-files.outputs.has_files == 'true'
        run: |
          echo "ğŸ” Iniciando escaneo de vulnerabilidades en archivos modificados..."
          echo "Umbral de riesgo: ${{ env.RISK_THRESHOLD }}"
          
          python scripts/vulnerability_scanner.py \
            --files-list changed_files.json \
            --model ${{ env.MODEL_PATH }} \
            --threshold ${{ env.RISK_THRESHOLD }} \
            --output reports/scan_results.json || echo "scan_failed=true" >> $GITHUB_OUTPUT
        continue-on-error: true
      
      - name: ğŸ“Š Generate HTML Report
        if: always() && steps.changed-files.outputs.has_files == 'true'
        run: |
          echo "ğŸ“Š Generando reporte HTML..."
          python scripts/report_generator.py reports/scan_results.json reports/scan_results.html
      
      - name: ğŸ“¤ Upload Reports as Artifacts
        if: always() && steps.changed-files.outputs.has_files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-reports-${{ github.sha }}
          path: |
            reports/scan_results.json
            reports/scan_results.html
            changed_files.json
          retention-days: 90
      
      - name: ğŸ“ Read Scan Results
        if: always() && steps.changed-files.outputs.has_files == 'true'
        id: results
        run: |
          if [ -f "reports/scan_results.json" ]; then
            TOTAL=$(jq -r '.total_files' reports/scan_results.json)
            HIGH=$(jq -r '.high_risk_count' reports/scan_results.json)
            MEDIUM=$(jq -r '.medium_risk_count' reports/scan_results.json)
            LOW=$(jq -r '.low_risk_count' reports/scan_results.json)
            PASSED=$(jq -r '.scan_passed' reports/scan_results.json)
            
            echo "total_files=$TOTAL" >> $GITHUB_OUTPUT
            echo "high_risk=$HIGH" >> $GITHUB_OUTPUT
            echo "medium_risk=$MEDIUM" >> $GITHUB_OUTPUT
            echo "low_risk=$LOW" >> $GITHUB_OUTPUT
            echo "scan_passed=$PASSED" >> $GITHUB_OUTPUT
            
            echo "ğŸ“Š Resultados del escaneo:"
            echo "   Total archivos: $TOTAL"
            echo "   Alto riesgo: $HIGH"
            echo "   Riesgo medio: $MEDIUM"
            echo "   Bajo riesgo: $LOW"
            echo "   Estado: $PASSED"
          fi
      
      - name: ğŸ’¬ Comment PR with Results
        if: github.event_name == 'pull_request' && always() && steps.changed-files.outputs.has_files == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            if (!fs.existsSync('reports/scan_results.json')) {
              console.log('No hay resultados para comentar');
              return;
            }
            
            const scanData = JSON.parse(fs.readFileSync('reports/scan_results.json', 'utf8'));
            
            const passed = scanData.scan_passed;
            const icon = passed ? 'âœ…' : 'âŒ';
            const status = passed ? 'APROBADO âœ“' : 'RECHAZADO âœ—';
            const statusColor = passed ? 'ğŸŸ¢' : 'ğŸ”´';
            
            let highRiskFiles = '';
            if (scanData.high_risk_files && scanData.high_risk_files.length > 0) {
              highRiskFiles = '\n### ğŸš¨ Archivos de Alto Riesgo Detectados\n\n';
              highRiskFiles += '| Archivo | Probabilidad | Nivel | Factores de Riesgo |\n';
              highRiskFiles += '|---------|-------------|-------|-------------------|\n';
              
              scanData.high_risk_files.slice(0, 15).forEach(file => {
                const detail = scanData.details.find(d => d.file === file);
                if (detail) {
                  const prob = (detail.risk_probability * 100).toFixed(1);
                  const level = detail.risk_level;
                  
                  // Extraer factores de riesgo
                  const features = detail.features || {};
                  const risks = [];
                  if (features.has_eval) risks.push('eval()');
                  if (features.has_exec) risks.push('exec()');
                  if (features.has_sql_concat) risks.push('SQL injection');
                  if (features.has_command_injection_risk) risks.push('Cmd injection');
                  if (features.has_hardcoded_secrets) risks.push('Secretos');
                  if (features.uses_subprocess_shell) risks.push('shell=True');
                  if (features.uses_weak_crypto) risks.push('Crypto dÃ©bil');
                  
                  const riskStr = risks.length > 0 ? risks.slice(0, 3).join(', ') : 'Varios';
                  
                  highRiskFiles += `| \`${file}\` | **${prob}%** | ${level} | ${riskStr} |\n`;
                }
              });
              
              if (scanData.high_risk_files.length > 15) {
                highRiskFiles += `\n*...y ${scanData.high_risk_files.length - 15} archivo(s) mÃ¡s. Ver reporte completo en artifacts.*\n`;
              }
            }
            
            const mediumRiskNote = scanData.medium_risk_count > 0 
              ? `\n> âš ï¸ **Nota**: Se detectaron ${scanData.medium_risk_count} archivo(s) con riesgo medio. Considera revisarlos.\n` 
              : '';
            
            const comment = `## ${icon} AnÃ¡lisis de Seguridad con Machine Learning
            
            **Estado del Escaneo:** ${statusColor} **${status}**
            
            ### ğŸ“Š Resumen de Vulnerabilidades
            
            | MÃ©trica | Cantidad |
            |---------|----------|
            | **Archivos analizados** | ${scanData.total_files} |
            | ğŸ”´ **Riesgo Alto** (â‰¥70%) | **${scanData.high_risk_count}** |
            | ğŸŸ¡ **Riesgo Medio** (40-69%) | ${scanData.medium_risk_count} |
            | ğŸŸ¢ **Riesgo Bajo** (<40%) | ${scanData.low_risk_count} |
            
            ${highRiskFiles}
            
            ${mediumRiskNote}
            
            ### ğŸ“¥ Reporte Detallado
            
            Descarga el reporte HTML completo desde los [**Artifacts**](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) de este workflow para anÃ¡lisis detallado con explicabilidad SHAP.
            
            ### ğŸ›¡ï¸ Recomendaciones de Seguridad
            
            ${passed ? 'âœ… Excelente trabajo! El cÃ³digo cumple con los estÃ¡ndares de seguridad.' : `
            âš ï¸ **AcciÃ³n Requerida**: Los archivos marcados requieren revisiÃ³n antes de merge:
            
            1. Revisa las vulnerabilidades detectadas por el modelo ML
            2. Aplica las correcciones de seguridad recomendadas
            3. Ejecuta el escaneo localmente: \`python scripts/vulnerability_scanner.py <archivo>\`
            4. Re-push los cambios para nueva validaciÃ³n
            `}
            
            ---
            
            <sub>ğŸ¤– Generado automÃ¡ticamente por **ML Security Scanner** | Random Forest Classifier | Umbral: ${process.env.RISK_THRESHOLD || '70%'}</sub>
            `;
            
            // Buscar comentario anterior del bot
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('AnÃ¡lisis de Seguridad con Machine Learning')
            );
            
            if (botComment) {
              // Actualizar comentario existente
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              // Crear nuevo comentario
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
      
      - name: ğŸš¨ Create GitHub Issue for Critical Vulnerabilities
        if: steps.results.outputs.high_risk > 3 && github.event_name == 'push'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const scanData = JSON.parse(fs.readFileSync('reports/scan_results.json', 'utf8'));
            
            let filesList = '';
            scanData.high_risk_files.forEach(file => {
              const detail = scanData.details.find(d => d.file === file);
              if (detail) {
                filesList += `\n#### ğŸ“„ \`${file}\`\n\n`;
                filesList += `- **Probabilidad de vulnerabilidad:** ${(detail.risk_probability * 100).toFixed(1)}%\n`;
                filesList += `- **Nivel de riesgo:** ${detail.risk_level}\n`;
                
                // Factores de riesgo
                const features = detail.features;
                const risks = [];
                if (features.has_eval) risks.push('âš ï¸ Uso de `eval()`');
                if (features.has_exec) risks.push('âš ï¸ Uso de `exec()`');
                if (features.has_sql_concat) risks.push('ğŸ›¡ï¸ SQL Injection detectado');
                if (features.has_command_injection_risk) risks.push('ğŸ’‰ Riesgo de inyecciÃ³n de comandos');
                if (features.has_hardcoded_secrets) risks.push('ğŸ”‘ Secretos hardcodeados');
                if (features.uses_subprocess_shell) risks.push('âš ï¸ `subprocess` con `shell=True`');
                if (features.has_pickle_load) risks.push('ğŸ“¦ DeserializaciÃ³n insegura (pickle)');
                if (features.uses_weak_crypto) risks.push('ğŸ” CriptografÃ­a dÃ©bil');
                if (features.has_path_traversal_risk) risks.push('ğŸ“ Riesgo de path traversal');
                
                if (risks.length > 0) {
                  filesList += `\n**Factores de riesgo detectados:**\n`;
                  risks.forEach(risk => filesList += `- ${risk}\n`);
                }
                filesList += '\n';
              }
            });
            
            const issueBody = `## ğŸš¨ Vulnerabilidades CrÃ­ticas Detectadas
            
            El escaneo automÃ¡tico de seguridad con Machine Learning ha identificado **${scanData.high_risk_count}** archivos con **alto riesgo** de vulnerabilidades en el commit [\`${context.sha.substring(0, 7)}\`](${context.payload.repository.html_url}/commit/${context.sha}).
            
            ### ğŸ“Š Resumen del AnÃ¡lisis
            
            | InformaciÃ³n | Valor |
            |------------|-------|
            | **Commit** | [\`${context.sha.substring(0, 7)}\`](${context.payload.repository.html_url}/commit/${context.sha}) |
            | **Branch** | \`${context.ref.replace('refs/heads/', '')}\` |
            | **Archivos analizados** | ${scanData.total_files} |
            | **ğŸ”´ Alto riesgo** | ${scanData.high_risk_count} |
            | **ğŸŸ¡ Riesgo medio** | ${scanData.medium_risk_count} |
            | **Autor** | @${context.actor} |
            
            ### ğŸ” Archivos Afectados
            
            ${filesList}
            
            ### ğŸ”§ Acciones Recomendadas
            
            1. **Revisar inmediatamente** los archivos marcados con alto riesgo
            2. **Aplicar correcciones** siguiendo las mejores prÃ¡cticas de seguridad:
               - Eliminar uso de \`eval()\` y \`exec()\`
               - Usar consultas parametrizadas para SQL
               - Validar y sanitizar todas las entradas de usuario
               - Usar algoritmos criptogrÃ¡ficos seguros (SHA256+, AES)
               - Evitar secretos hardcodeados (usar variables de entorno)
            3. **Ejecutar escaneo local**: \`python scripts/vulnerability_scanner.py <archivo>\`
            4. **Verificar cambios** y hacer commit de las correcciones
            5. **Revisar el reporte HTML** completo en los artifacts del workflow
            
            ### ğŸ“š Recursos de Seguridad
            
            - [OWASP Build if Critical Vulnerabilities Found
        if: steps.results.outputs.scan_passed == 'false'
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âŒ ESCANEO DE SEGURIDAD FALLÃ“"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          echo "ğŸš¨ Se detectaron ${{ steps.results.outputs.high_risk }} vulnerabilidades CRÃTICAS"
          echo ""
          echo "ğŸ“Š EstadÃ­sticas:"
          echo "   - Archivos analizados: ${{ steps.results.outputs.total_files }}"
          echo "   - ğŸ”´ Alto riesgo: ${{ steps.results.outputs.high_risk }}"
          echo "   - ğŸŸ¡ Medio riesgo: ${{ steps.results.outputs.medium_risk }}"
          echo "   - ğŸŸ¢ Bajo riesgo: ${{ steps.results.outputs.low_risk }}"
          echo ""
          echo "âš ï¸  El cÃ³digo NO cumple con los estÃ¡ndares de seguridad"
          echo "âš ï¸  Este PR/commit serÃ¡ BLOQUEADO hasta que se corrijan las vulnerabilidades"
          echo ""
          echo "ğŸ“¥ Descarga el reporte detallado desde los Artifacts"
          echo "ğŸ”§ Ejecuta localmente: python scripts/vulnerability_scanner.py <archivo>"
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          exit 1
      
      - name: âœ… Security Scan Passed
        if: steps.results.outputs.scan_passed == 'true' || steps.changed-files.outputs.has_files == 'false'
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… ESCANEO DE SEGURIDAD EXITOSO"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          if [ "${{ steps.changed-files.outputs.has_files }}" = "true" ]; then
            echo "ğŸ‰ No se detectaron vulnerabilidades crÃ­ticas"
            echo ""
            echo "ğŸ“Š Archivos analizados: ${{ steps.results.outputs.total_files }}"
            echo "   - ğŸ”´ Alto riesgo: ${{ steps.results.outputs.high_risk }}"
            echo "   - ğŸŸ¡ Medio riesgo: ${{ steps.results.outputs.medium_risk }}"
            echo "   - ğŸŸ¢ Bajo riesgo: ${{ steps.results.outputs.low_risk }}"
          else
            echo "â„¹ï¸  No se encontraron archivos Python/JavaScript para escanear"
          fi
          echo ""
          echo "âœ… El cÃ³digo cumple con los estÃ¡ndares de seguridad"
          echo "âœ… Este PR/commit puede ser mergeado de forma segura"
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” que todas las vulnerabilidades hayan sido corregidas y el escaneo pase exitosamente.</sub>
            `;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ [SECURITY] ${scanData.high_risk_count} vulnerabilidades crÃ­ticas - Commit ${context.sha.substring(0, 7)}`,
              body: issueBody,
              labels: ['security', 'vulnerability', 'high-priority', 'automated'],
              assignees: [context.actor]
            });
      
      - name: âŒ Fail if vulnerabilities found
        if: steps.results.outputs.SCAN_PASSED == 'false'
        run: |
          echo "âŒ Escaneo FALLÃ“: Se detectaron ${{ steps.results.outputs.HIGH_RISK }} vulnerabilidades de alto riesgo"
          echo ""
          echo "Archivos afectados:"
          echo "${{ steps.results.outputs.HIGH_RISK_FILES }}"
          exit 1
      
      - name: âœ… Success
        if: steps.results.outputs.SCAN_PASSED == 'true'
        run: |
          echo "âœ… Escaneo EXITOSO: No se detectaron vulnerabilidades de alto riesgo"
          echo "ğŸ“Š Archivos analizados: ${{ steps.results.outputs.TOTAL_FILES }}"
