"""
Script principal para an√°lisis de vulnerabilidades con ML.
Se ejecuta en el pipeline de CI/CD para analizar c√≥digo en cada commit/PR.
"""

import sys
import os
import json
from pathlib import Path
from typing import Dict, List

# Agregar paths
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from scripts.code_analyzer import CodeAnalyzer, analyze_directory
from ml_model.model import VulnerabilityPredictor


class VulnerabilityScanner:
    """Scanner principal de vulnerabilidades"""
    
    RISK_THRESHOLD = 0.70  # 70% como indica el requerimiento
    
    def __init__(self, model_path: str):
        """
        Inicializa el scanner
        
        Args:
            model_path: Ruta al modelo ML entrenado
        """
        self.predictor = VulnerabilityPredictor(model_path)
        self.results = []
    
    def scan_directory(self, directory: str) -> List[Dict]:
        """
        Escanea un directorio completo (Python y JavaScript)
        
        Args:
            directory: Directorio a escanear
            
        Returns:
            Lista de resultados del an√°lisis
        """
        print(f"\nüîç Escaneando directorio: {directory}")
        print("=" * 60)
        
        # Buscar archivos Python y JavaScript
        target_files = []
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.endswith(('.py', '.js')):
                    target_files.append(os.path.join(root, file))
        
        print(f"üìÅ Archivos encontrados: {len(target_files)}")
        python_files = [f for f in target_files if f.endswith('.py')]
        js_files = [f for f in target_files if f.endswith('.js')]
        print(f"   Python (.py): {len(python_files)}")
        print(f"   JavaScript (.js): {len(js_files)}")
        print()
        
        vulnerabilities_found = 0
        high_risk_files = []
        
        # Analizar cada archivo
        for filepath in target_files:
            try:
                result = self.scan_file(filepath)
                
                if 'error' in result:
                    print(f"‚ö†Ô∏è  Error analizando {filepath}: {result['error']}")
                    continue
                
                self.results.append(result)
                
                # Estad√≠sticas
                if result['risk_probability'] >= self.RISK_THRESHOLD:
                    vulnerabilities_found += 1
                    high_risk_files.append(filepath)
                    file_type = "üêç Python" if filepath.endswith('.py') else "üìú JavaScript"
                    print(f"üö® ALERTA [{file_type}]: {filepath}")
                    print(f"   Probabilidad de vulnerabilidad: {result['risk_probability']:.2%}")
                    print(f"   Nivel de riesgo: {result['risk_level']}")
                    self._print_risk_factors(result['features'])
                    print()
            except Exception as e:
                print(f"‚ö†Ô∏è  Error procesando {filepath}: {str(e)}")
                continue
        
        # Resumen
        print("=" * 60)
        print(f"\nüìä Resumen del escaneo:")
        print(f"   Total de archivos analizados: {len(self.results)}")
        print(f"   Vulnerabilidades detectadas: {vulnerabilities_found}")
        print(f"   Archivos de alto riesgo (>70%): {len(high_risk_files)}")
        
        return self.results
    
    def scan_file(self, filepath: str) -> Dict:
        """
        Escanea un √∫nico archivo
        
        Args:
            filepath: Ruta al archivo
            
        Returns:
            Resultado del an√°lisis
        """
        analyzer = CodeAnalyzer()
        result = analyzer.analyze_file(filepath)
        
        if 'error' in result:
            return {
                'file': filepath,
                'error': result['error'],
                'vulnerable': False,
                'risk_probability': 0.0
            }
        
        features = result['features']
        features_df = self.predictor.prepare_features(features)
        prediction, probability = self.predictor.predict(features_df)
        
        return {
            'file': filepath,
            'vulnerable': bool(prediction),
            'risk_probability': probability,
            'risk_level': self._get_risk_level(probability),
            'features': features
        }
    
    def _get_risk_level(self, probability: float) -> str:
        """Determina el nivel de riesgo basado en la probabilidad"""
        if probability >= 0.90:
            return "CR√çTICO"
        elif probability >= 0.70:
            return "ALTO"
        elif probability >= 0.40:
            return "MEDIO"
        else:
            return "BAJO"
    
    def _print_risk_factors(self, features: Dict):
        """Imprime los factores de riesgo detectados"""
        risk_factors = []
        
        # Patrones cr√≠ticos
        if features.get('has_eval'):
            risk_factors.append("Uso de eval()")
        if features.get('has_exec'):
            risk_factors.append("Uso de exec()")
        if features.get('has_sql_concat'):
            risk_factors.append("SQL injection (concatenaci√≥n)")
        if features.get('has_command_injection_risk'):
            risk_factors.append("Riesgo de inyecci√≥n de comandos")
        if features.get('has_hardcoded_secrets'):
            risk_factors.append("Secretos hardcodeados")
        if features.get('uses_subprocess_shell'):
            risk_factors.append("subprocess con shell=True")
        if features.get('has_pickle_load'):
            risk_factors.append("Deserializaci√≥n insegura (pickle)")
        if features.get('has_unsafe_deserialization'):
            risk_factors.append("Deserializaci√≥n insegura")
        if features.get('uses_weak_crypto'):
            risk_factors.append("Criptograf√≠a d√©bil")
        if features.get('has_path_traversal_risk'):
            risk_factors.append("Riesgo de path traversal")
        
        if risk_factors:
            print(f"   Factores de riesgo detectados:")
            for factor in risk_factors:
                print(f"      - {factor}")
    
    def generate_summary_report(self) -> Dict:
        """Genera reporte resumen del escaneo"""
        if not self.results:
            return {'error': 'No hay resultados para reportar'}
        
        high_risk = [r for r in self.results if r['risk_probability'] >= self.RISK_THRESHOLD]
        medium_risk = [r for r in self.results if 0.4 <= r['risk_probability'] < 0.7]
        low_risk = [r for r in self.results if r['risk_probability'] < 0.4]
        
        summary = {
            'total_files': len(self.results),
            'high_risk_count': len(high_risk),
            'medium_risk_count': len(medium_risk),
            'low_risk_count': len(low_risk),
            'high_risk_files': [r['file'] for r in high_risk],
            'scan_passed': len(high_risk) == 0,
            'details': self.results
        }
        
        return summary
    
    def save_results(self, output_path: str):
        """Guarda los resultados en JSON"""
        summary = self.generate_summary_report()
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Resultados guardados en: {output_path}")


def main():
    """Funci√≥n principal"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Esc√°ner de vulnerabilidades con Machine Learning'
    )
    parser.add_argument(
        'target',
        help='Directorio o archivo a escanear'
    )
    parser.add_argument(
        '--model',
        default='ml_model/vulnerability_detector.pkl',
        help='Ruta al modelo ML'
    )
    parser.add_argument(
        '--output',
        default='reports/scan_results.json',
        help='Archivo de salida para resultados'
    )
    parser.add_argument(
        '--threshold',
        type=float,
        default=0.70,
        help='Umbral de probabilidad para alertas (default: 0.70)'
    )
    
    args = parser.parse_args()
    
    # Verificar que existe el modelo
    if not os.path.exists(args.model):
        print(f"‚ùå Error: Modelo no encontrado en {args.model}")
        print("   Ejecuta primero: python ml_model/model.py")
        sys.exit(1)
    
    # Crear scanner
    scanner = VulnerabilityScanner(args.model)
    scanner.RISK_THRESHOLD = args.threshold
    
    # Escanear
    if os.path.isdir(args.target):
        scanner.scan_directory(args.target)
    elif os.path.isfile(args.target):
        result = scanner.scan_file(args.target)
        scanner.results = [result]
        
        if result['risk_probability'] >= scanner.RISK_THRESHOLD:
            print(f"üö® ALERTA: {result['file']}")
            print(f"   Probabilidad: {result['risk_probability']:.2%}")
            print(f"   Nivel: {result['risk_level']}")
        else:
            print(f"‚úÖ Archivo seguro: {result['file']}")
            print(f"   Probabilidad de vulnerabilidad: {result['risk_probability']:.2%}")
    else:
        print(f"‚ùå Error: {args.target} no existe")
        sys.exit(1)
    
    # Guardar resultados
    scanner.save_results(args.output)
    
    # Generar reporte HTML autom√°ticamente
    html_path = args.output.replace('.json', '.html')
    try:
        from scripts.report_generator import generate_html_report
        generate_html_report(args.output, html_path)
        print(f"üìÑ Reporte HTML: {html_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è  No se pudo generar HTML: {e}")
    
    # Exit code basado en vulnerabilidades encontradas
    summary = scanner.generate_summary_report()
    if summary['high_risk_count'] > 0:
        print(f"\n‚ùå Escaneo FALL√ì: {summary['high_risk_count']} vulnerabilidades detectadas")
        sys.exit(1)
    else:
        print(f"\n‚úÖ Escaneo EXITOSO: No se detectaron vulnerabilidades de alto riesgo")
        sys.exit(0)


if __name__ == '__main__':
    main()
